from dotenv import load_dotenv
load_dotenv()
import os
import sys
from openai import OpenAI
from utils.logger import get_logger

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
logger = get_logger(__name__)

def build_prompt(
        product: dict,
    ) -> dict:
    return f"""
    - ìƒí’ˆëª…: {product['name']}
    - ì¹´í…Œê³ ë¦¬: {product['category']}
    - ê°€ê²©: {product['price']}ì›
    - ë¸Œëœë“œ: {product['brand']}
    - íŠ¹ì§•: {product['features']}
    """


def generate_background_prompt(product: dict) -> str | None:
    """
    ì œí’ˆ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, í•´ë‹¹ ì œí’ˆì— ì–´ìš¸ë¦¬ëŠ” ë°°ê²½ ìƒì„±ìš© ì˜ì–´ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ì˜ˆ: "a wooden bathroom shelf with soft natural light, suitable for skincare product"
    """
    try:
        system_prompt = (
            "You are a prompt designer for AI image generation.\n\n"
            "Based on the product description in Korean, write an English prompt that shows a person naturally using the product.\n\n"
            "- The person can be fully visible (face allowed) but the product must be the main focus.\n"
            "- Make the scene realistic and relatable, like a lifestyle photo.\n"
            "- Avoid distractions: no unnecessary objects, no text overlays, no logos.\n"
            "- The background should complement the product, not overpower it.\n"
            "- Output one short sentence in English, under 15 words."
        )

        user_prompt = build_prompt(product)

        logger.debug(f"ğŸ› ï¸ ë°°ê²½ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œì‘")
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
        )

        prompt_text = response.choices[0].message.content.strip()
        logger.info(f"âœ… ìƒì„±ëœ ë°°ê²½ í”„ë¡¬í”„íŠ¸: {prompt_text}")
        return prompt_text

    except Exception as e:
        logger.error(f"âŒ ë°°ê²½ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return None


def generate_human_prompt(product: dict) -> str | None:
    """
    ì‚¬ëŒì´ ì œí’ˆì„ ì‚¬ìš©í•˜ëŠ” ì¥ë©´ì„ ë¬˜ì‚¬í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±
    """
    try:
        system_prompt = (
            "You are a visual prompt engineer. Based on the product description in Korean, "
            "list visual elements that should NOT appear in the image so the product remains the main focus.\n"
            "- Exclude text, logos, busy patterns, excessive clutter, irrelevant objects, and flashy colors.\n"
            "- Do NOT exclude faces or people.\n"
            "- Output a comma-separated list of keywords only.\n"
            "- Example: text, logo, clutter, busy background, bright colors, excessive objects."
        )

        user_prompt = build_prompt(product)  # ê¸°ì¡´ ì œí’ˆ ìš”ì•½ í•œêµ­ì–´ ë¬¸ìì—´

        logger.debug(f"ğŸ› ï¸ ì‚¬ëŒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œì‘")
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
        )

        human_prompt = response.choices[0].message.content.strip()
        logger.info(f"âœ… ìƒì„±ëœ ì‚¬ëŒ í”„ë¡¬í”„íŠ¸: {human_prompt}")
        return human_prompt

    except Exception as e:
        logger.error(f"âŒ ì‚¬ëŒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return None


def generate_negative_prompt(product: dict) -> str | None:
    """
    ì œí’ˆê³¼ ê²¹ì¹˜ì§€ ì•ŠëŠ” ë°°ê²½ì„ ë§Œë“¤ê¸° ìœ„í•´, ë°°ì œí•  ìš”ì†Œ(negative prompt)ë¥¼ ì˜ì–´ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        system_prompt = (
            "You are a visual prompt engineer. Based on the product description in Korean, "
            "list visual elements that should NOT appear in the background so the product stands out clearly.\n"
            "- Include things like distracting textures, objects, people, or strong visual elements.\n"
            "- Always exclude face, eyes, portrait, logo, text, busy patterns, and bright or flashy colors.\n"
            "- Output a comma-separated list of keywords only, not full sentences.\n"
            "- Example: face, eyes, portrait, hands, logo, text, clutter, bright colors, busy background, background people."
        )

        user_prompt = build_prompt(product)  # ê¸°ì¡´ ì œí’ˆ ìš”ì•½ í•œêµ­ì–´ ë¬¸ìì—´

        logger.debug(f"ğŸ› ï¸ ë¶€ì • í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œì‘")
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
        )

        neg_prompt = response.choices[0].message.content.strip()
        logger.info(f"âœ… ìƒì„±ëœ ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸: {neg_prompt}")
        return neg_prompt

    except Exception as e:
        logger.error(f"âŒ ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def generate_prompts(product: dict, mode: str = "background") -> dict:
    """
    mode: "background" or "human"
    """
    if mode == "human":
        prompt = generate_human_prompt(product)
    else:
        prompt = generate_background_prompt(product)

    neg_prompt = generate_negative_prompt(product)
    return {
        "background_prompt": prompt,
        "negative_prompt": neg_prompt
    }


def classify_product(product: dict) -> str | None:
    """
    OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì œí’ˆì„ ìƒì˜/í•˜ì˜/ì„¸íŠ¸/ì‹ ë°œ/ì¥ê°‘/ëª¨ì ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.

    Args:
        product (dict): ì œí’ˆ ì •ë³´ (ì˜ˆ: {"name": "ìŠ¤íŠ¸ë¼ì´í”„ ì…”ì¸ ", "category": "íŒ¨ì…˜", "price": 30000, "brand": "ABC", "features": "ë©´ì†Œì¬, ì—¬ë¦„ìš©"})

    Returns:
        str: ë¶„ë¥˜ ê²°ê³¼ ("ìƒì˜", "í•˜ì˜", "ì„¸íŠ¸", "ì‹ ë°œ", "ì¥ê°‘", "ëª¨ì") ì¤‘ í•˜ë‚˜
    """
    try:
        system_prompt = (
            "ë‹¹ì‹ ì€ íŒ¨ì…˜ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n\n"
            "ì£¼ì–´ì§„ ì œí’ˆ ì •ë³´ë¥¼ ì½ê³ , ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µí•˜ì„¸ìš”:\n"
            "- ìƒì˜\n- í•˜ì˜\n- ì„¸íŠ¸\n- ì‹ ë°œ\n- ì¥ê°‘\n- ëª¨ì\n\n"
            "ê·œì¹™:\n"
            "- ë°˜ë“œì‹œ ì •í™•íˆ ìœ„ 6ê°œ ë‹¨ì–´ ì¤‘ í•˜ë‚˜ë¡œë§Œ ì¶œë ¥\n"
            "- ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¬¸ì¥ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”\n"
            "- ëª¨ë¥´ë©´ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ê²ƒìœ¼ë¡œ ì¶”ì •í•˜ì„¸ìš”"
        )

        user_prompt = f"""
        ìƒí’ˆ ì •ë³´:
        - ìƒí’ˆëª…: {product['name']}
        - ì¹´í…Œê³ ë¦¬: {product['category']}
        - ê°€ê²©: {product['price']}ì›
        - ë¸Œëœë“œ: {product['brand']}
        - íŠ¹ì§•: {product['features']}
        """

        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0,
        )

        result = response.choices[0].message.content.strip()
        logger.info(f"âœ… ì œí’ˆ ë¶„ë¥˜ ê²°ê³¼: {result}")
        return result

    except Exception as e:
        logger.error(f"âŒ ì œí’ˆ ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
        return None
