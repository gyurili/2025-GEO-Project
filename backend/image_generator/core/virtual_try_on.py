import datetime
import os
import torch
from PIL import Image
from diffusers import AutoPipelineForInpainting, AutoencoderKL, ControlNetModel
from controlnet_aux import MidasDetector
from diffusers.utils import load_image
from huggingface_hub import snapshot_download
from utils.logger import get_logger

logger = get_logger(__name__)

class VirtualTryOnPipeline:
    def __init__(self, model_dir="./backend/models"):
        """
        ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        ëª¨ë“  ëª¨ë¸ì€ "./backend/models" ê²½ë¡œì— ë‹¤ìš´ë¡œë“œë˜ê±°ë‚˜ ë¡œë“œë¨
        """
        logger.debug("ğŸ› ï¸ VirtualTryOnPipeline ì´ˆê¸°í™” ì‹œì‘")
        self.model_dir = model_dir
        os.makedirs(self.model_dir, exist_ok=True)

        self.pipeline = None
        self.vae = None
        self.controlnet = None
        self.midas_detector = None
        logger.info(f"âœ… VirtualTryOnPipeline ì´ˆê¸°í™” ì™„ë£Œ. ëª¨ë¸ì€ '{self.model_dir}'ì—ì„œ ë¡œë“œ/ì €ì¥")
        self._load_models()

    def _download_and_load_models(self, model_name_or_path, subfolder=None, model_class=None, **kwargs):
        """
        ëª¨ë¸ì„ ë¡œì»¬ì— ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ ë¡œë“œí•©ë‹ˆë‹¤.
        kwargsëŠ” from_pretrainedì— ì „ë‹¬í•œ ì¶”ê°€ ì¸ìì…ë‹ˆë‹¤.
        """
        local_path = os.path.join(self.model_dir, model_name_or_path.replace("/", "_"))  # ë¡œì»¬ í´ë”ëª… ìƒì„±

        # ë‹¤ìš´ë¡œë“œ í™•ì¸
        if not os.path.exists(local_path):
            logger.debug(f"ğŸ› ï¸ {model_name_or_path} ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            snapshot_download(repo_id=model_name_or_path, local_dir=local_path)
            logger.info(f"âœ… {model_name_or_path} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {local_path}")
        else:
            logger.info(f"âœ… {model_name_or_path} ëª¨ë¸ì´ ì´ë¯¸ ì¡´ì¬: {local_path}")
        
        if model_class:
            if subfolder: # íŠ¹ì • ì„œë¸Œí´ë”ê°€ ìˆëŠ” ê²½ìš°
                return model_class.from_pretrained(os.path.join(local_path, subfolder), **kwargs)
            else: # ì„œë¸Œí´ë” ì—†ì´ ë°”ë¡œ ë¡œë“œí•˜ëŠ” ê²½ìš°
                return model_class.from_pretrained(local_path, **kwargs)
        return local_path

    def _load_models(self):
        """ëª¨ë“  í•„ìš”í•œ ëª¨ë¸ë“¤ì„ ë¡œì»¬ì—ì„œ ë¡œë“œí•˜ê±°ë‚˜ ë‹¤ìš´ë¡œë“œ í•©ë‹ˆë‹¤."""
        logger.debug("ğŸ› ï¸ VAE ë¡œë”© ì‹œì‘")
        vae_path = self._download_and_load_models(
            "madebyollin/sdxl-vae-fp16-fix",
            model_class=AutoencoderKL,
            torch_dtype=torch.float16
        )
        self.vae = vae_path
        logger.info("âœ… VAE ë¡œë”© ì™„ë£Œ")

        logger.debug("ğŸ› ï¸ Depth Detector ë¡œë”© ì‹œì‘")
        controlnet_aux_repo_path = self._download_and_load_models("lllyasviel/ControlNet")
        midas_model_dir_for_detector = os.path.join(controlnet_aux_repo_path, "annotator", "ckpts")
        self.midas_detector = MidasDetector.from_pretrained(midas_model_dir_for_detector, model_type="dpt_hybrid")
        logger.info("âœ… Depth Detector ë¡œë”© ì™„ë£Œ")

        logger.debug("ğŸ› ï¸ ControlNet (Depth) ë¡œë”© ì‹œì‘")
        controlnet_depth_path = self._download_and_load_models(
            "diffusers/controlnet-depth-sdxl-1.0",
            model_class=ControlNetModel,
            torch_dtype=torch.float16
        )
        self.controlnet = controlnet_depth_path
        logger.info("âœ… ControlNet (Depth) ë¡œë”© ì™„ë£Œ")

        logger.debug("ğŸ› ï¸ Pipeline ë¡œë”© ì‹œì‘")
        self.pipeline = AutoPipelineForInpainting.from_pretrained(
            "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
            vae=self.vae, # ë¡œë“œëœ VAE ê°ì²´ ì „ë‹¬
            controlnet=self.controlnet, # ë¡œë“œëœ ControlNet ê°ì²´ ì „ë‹¬
            torch_dtype=torch.float16,
            variant="fp16",
            use_safetensors=True
        ).to("cuda")
        logger.info("âœ… Pipeline ë¡œë”© ì™„ë£Œ")

        logger.debug("ğŸ› ï¸ IP-Adapter ëª¨ë¸ ë¡œë”© ì‹œì‘")
        ip_adapter_repo_path = self._download_and_load_models("h94/IP-Adapter")
        ip_adapter_model_path = os.path.join(ip_adapter_repo_path, "sdxl_models", "ip-adapter_sdxl.bin")
        self.pipeline.load_ip_adapter(
            ip_adapter_repo_path,
            subfolder="sdxl_models",
            weight_name="ip-adapter_sdxl.bin",
            low_cpu_mem_usage=True
        )
        self.pipeline.set_ip_adapter_scale(3.0)
        logger.info("âœ… IP-Adapter ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

        logger.debug("ğŸ› ï¸ LoRA ë¡œë”© ì‹œì‘")
        lora_path = self._download_and_load_models(
            "Norod78/weird-fashion-show-outfits-sdxl-lora",
            model_class=None,
        )
        self.pipeline.load_lora_weights(lora_path, weight_name='sdxl-WeirdOutfit-Dreambooh.safetensors')
        logger.info("âœ… LoRA ë¡œë”© ì™„ë£Œ")
        logger.info("âœ… ëª¨ë“  ëª¨ë¸ ë¡œë”© ë° ì¤€ë¹„ ì™„ë£Œ.")

    def try_on(self, image_path, ip_image_path, mask_image_path, prompt, negative_prompt,
               width=512, height=768, controlnet_conditioning_scale=0.7,
               strength=0.99, guidance_scale=7.5, num_inference_steps=100, seed=None):
        """
        ê°€ìƒ í”¼íŒ…ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        logger.debug("ğŸ› ï¸ ì…ë ¥ ì´ë¯¸ì§€ ë¡œë”©")
        image = load_image(image_path).convert("RGB")
        ip_image = load_image(ip_image_path).convert("RGB")
        mask_image = load_image(mask_image_path)

        logger.debug("ğŸ› ï¸ ControlNet ì œì–´ ì´ë¯¸ì§€ ìƒì„±")
        control_image_depth = self.midas_detector(image)

        if seed is None:
            now = datetime.datetime.now()
            seed = int(now.strftime("%Y%m%d%H%M%S"))
        generator = torch.manual_seed(seed)
        logger.debug(f"ğŸ› ï¸ ë‚ ì§œ ì‹œë“œ: {seed}")

        logger.debug(f"ğŸ› ï¸ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘")
        final_image = self.pipeline(
            prompt=prompt,
            negative_prompt=negative_prompt,
            width=width,
            height=height,
            image=image,
            mask_image=mask_image,
            ip_adapter_image=ip_image,
            control_image=control_image_depth,
            controlnet_conditioning_scale=controlnet_conditioning_scale,
            strength=strength,
            guidance_scale=guidance_scale,
            num_inference_steps=num_inference_steps,
            generator=generator,
        ).images[0]
        logger.info(f"âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ")
        return final_image


def run_virtual_tryon(
    image_path: str,
    ip_image_path: str,
    mask_image_path: str,
    prompt: str,
    negative_prompt: str,
    vae_model: str = "madebyollin/sdxl-vae-fp16-fix",
    controlnet_model: str = "diffusers/controlnet-depth-sdxl-1.0",
    pipeline_model: str = "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
    ip_adapter_repo: str = "h94/IP-Adapter",
    ip_adapter_subfolder: str = "sdxl_models",
    ip_adapter_weight: str = "ip-adapter_sdxl.bin",
    ip_adapter_scale: float = 0.8,
    lora_repo: str = "Norod78/weird-fashion-show-outfits-sdxl-lora",
    lora_weight: str = "sdxl-WeirdOutfit-Dreambooh.safetensors",
    width: int = 512,
    height: int = 768,
    controlnet_conditioning_scale: float = 0.7,
    strength: float = 0.99,
    guidance_scale: float = 7.5,
    num_inference_steps: int = 100,
    seed: int = None,
):
    """
    ì£¼ì–´ì§„ ì´ë¯¸ì§€, ë§ˆìŠ¤í¬, ì˜ìƒ ì´ë¯¸ì§€ì— ëŒ€í•´ ê°€ìƒ í”¼íŒ… ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Parameters:
        image_path (str): ëª¨ë¸ ì´ë¯¸ì§€ ê²½ë¡œ
        ip_image_path (str): ì˜ìƒ ì´ë¯¸ì§€ ê²½ë¡œ (ë°°ê²½ ì œê±°ëœ ì˜· ì´ë¯¸ì§€)
        mask_image_path (str): ì˜·ì„ ì…í ì˜ì—­ì˜ ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ê²½ë¡œ
        prompt (str): ê¸ì • í”„ë¡¬í”„íŠ¸ (ì´ë¯¸ì§€ ìƒì„± ë°©í–¥)
        negative_prompt (str): ë¶€ì • í”„ë¡¬í”„íŠ¸ (íšŒí”¼í•  íŠ¹ì§•)
        vae_model (str): VAE ëª¨ë¸ ê²½ë¡œ ë˜ëŠ” í—ˆê¹…í˜ì´ìŠ¤ ID
        controlnet_model (str): ControlNet ëª¨ë¸ ê²½ë¡œ ë˜ëŠ” ID
        pipeline_model (str): Stable Diffusion Inpainting ëª¨ë¸ ê²½ë¡œ ë˜ëŠ” ID
        ip_adapter_repo (str): IP-Adapter í—ˆê¹…í˜ì´ìŠ¤ repo ID
        ip_adapter_subfolder (str): IP-Adapter ëª¨ë¸ ì„œë¸Œí´ë”
        ip_adapter_weight (str): IP-Adapter ê°€ì¤‘ì¹˜ íŒŒì¼ëª…
        ip_adapter_scale (float): IP-Adapter scale ê°’
        lora_repo (str): LoRA ëª¨ë¸ repo ID
        lora_weight (str): ì‚¬ìš©í•  safetensors íŒŒì¼ ì´ë¦„
        width (int): ìƒì„± ì´ë¯¸ì§€ ë„ˆë¹„
        height (int): ìƒì„± ì´ë¯¸ì§€ ë†’ì´
        controlnet_conditioning_scale (float): ControlNet ë°˜ì˜ ë¹„ìœ¨
        strength (float): Inpainting strength
        guidance_scale (float): Classifier-free guidance scale
        num_inference_steps (int): ìƒì„± ìŠ¤í… ìˆ˜
        seed (int, optional): ìƒì„± ì‹œë“œ (Noneì´ë©´ í˜„ì¬ ì‹œê°„ ê¸°ì¤€)

    Returns:
        PIL.Image.Image: ìƒì„±ëœ ê°€ìƒ í”¼íŒ… ì´ë¯¸ì§€
    """
    logger.debug("ğŸ› ï¸ ì…ë ¥ ì´ë¯¸ì§€ ë¡œë”© ì‹œì‘")
    image = load_image(image_path).convert("RGB")
    ip_image = load_image(ip_image_path).convert("RGB")
    mask_image = load_image(mask_image_path)
    logger.info("âœ… ì…ë ¥ ì´ë¯¸ì§€, ì˜ìƒ ì´ë¯¸ì§€, ë§ˆìŠ¤í¬ ë¡œë”© ì™„ë£Œ")

    logger.debug("ğŸ› ï¸ Midas Depth ì œì–´ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘")
    midas_detector = MidasDetector.from_pretrained("lllyasviel/ControlNet")
    control_image_depth = midas_detector(image).resize((width, height)).convert("RGB")
    logger.info("âœ… Depth ì œì–´ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ")

    logger.debug("ğŸ› ï¸ VAE ëª¨ë¸ ë¡œë”© ì‹œì‘")
    vae = AutoencoderKL.from_pretrained(vae_model, torch_dtype=torch.float16)
    logger.info("âœ… VAE ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

    logger.debug("ğŸ› ï¸ ControlNet ëª¨ë¸ ë¡œë”© ì‹œì‘")
    controlnet = ControlNetModel.from_pretrained(
        controlnet_model,
        torch_dtype=torch.float16
    )
    logger.info("âœ… ControlNet ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

    logger.debug("ğŸ› ï¸ íŒŒì´í”„ë¼ì¸ ë¡œë”© ì‹œì‘")
    pipeline = AutoPipelineForInpainting.from_pretrained(
        pipeline_model,
        vae=vae,
        torch_dtype=torch.float16,
        variant="fp16",
        use_safetensors=True
    ).to("cuda")
    pipeline.controlnet = controlnet
    logger.info("âœ… íŒŒì´í”„ë¼ì¸ ë¡œë”© ë° ControlNet ì£¼ì… ì™„ë£Œ")

    logger.debug("ğŸ› ï¸ IP-Adapter ë¡œë”© ì‹œì‘")
    pipeline.load_ip_adapter(
        ip_adapter_repo,
        subfolder=ip_adapter_subfolder,
        weight_name=ip_adapter_weight,
        low_cpu_mem_usage=True
    )
    pipeline.set_ip_adapter_scale(ip_adapter_scale)
    logger.info("âœ… IP-Adapter ë¡œë”© ë° ìŠ¤ì¼€ì¼ ì„¤ì • ì™„ë£Œ")

    logger.debug("ğŸ› ï¸ LoRA ë¡œë”© ì‹œì‘")
    pipeline.load_lora_weights(lora_repo, weight_name=lora_weight)
    logger.info("âœ… LoRA ë¡œë”© ì™„ë£Œ")

    if seed is None:
        now = datetime.datetime.now()
        seed = int(now.strftime("%Y%m%d%H%M%S"))
    generator = torch.manual_seed(seed)
    logger.info(f"ğŸ² ì‹œë“œ ì„¤ì • ì™„ë£Œ: {seed}")

    logger.debug("ğŸ› ï¸ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘")
    final_image = pipeline(
        prompt=prompt,
        negative_prompt=negative_prompt,
        width=width,
        height=height,
        image=image,
        mask_image=mask_image,
        ip_adapter_image=ip_image,
        control_image=control_image_depth,
        controlnet_conditioning_scale=controlnet_conditioning_scale,
        strength=strength,
        guidance_scale=guidance_scale,
        num_inference_steps=num_inference_steps,
        generator=generator,
    ).images[0]
    logger.info("âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ")

    return final_image