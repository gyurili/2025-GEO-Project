import os
import torch
from dotenv import load_dotenv
from transformers import AutoModel, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
from diffusers import (
    AutoPipelineForInpainting,
    AutoPipelineForText2Image,
    ControlNetModel,
    StableDiffusionPipeline,
    AutoencoderKL
)
from controlnet_aux import MidasDetector
from peft import PeftModel
from utils.logger import get_logger

logger = get_logger(__name__)

load_dotenv()

MODEL_LOADERS = {
    "diffusion_pipeline": AutoPipelineForInpainting,
    "diffusion_text2img": AutoPipelineForText2Image,
    "vae": AutoencoderKL,
    "controlnet": ControlNetModel,
    "casual_lm": AutoModelForCausalLM,
    "encoder": AutoModel,
}

def download_model(
        model_id: str, 
        model_type: str = "diffusion_text2img",
        save_dir: str = "./backend/models",
        use_4bit: bool = False
    ):
    """
    Hugging Faceì—ì„œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì§€ì •ëœ ê²½ë¡œì— ì €ì¥
    ëª¨ë¸ ìœ í˜•ì— ë”°ë¼ í™•ì¥ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„
    CPU/GPU í™˜ê²½ì— ë”°ë¼ torch_dtypeì„ ì„¤ì •

    Args:
        model_id (str): Hugging Face ëª¨ë¸ ID (ì˜ˆ: "stabilityai/stable-diffusion-xl-base-1.0").
        model_type (str): ëª¨ë¸ ìœ í˜• (ì˜ˆ: "diffusion_text2img", "causal_lm", "encoder" ë“±).
        save_dir (str, optional): ëª¨ë¸ì„ ì €ì¥í•  ê¸°ë³¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ.
                                  ê¸°ë³¸ê°’ì€ "./backend/models".

    Returns:
        str: ëª¨ë¸ì´ ì €ì¥ëœ ìµœì¢… ê²½ë¡œ. ë‹¤ìš´ë¡œë“œ ë˜ëŠ” ì €ì¥ì— ì‹¤íŒ¨í•˜ë©´ None ë°˜í™˜.
    """
    if model_type not in MODEL_LOADERS:
        logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ ìœ í˜•: {model_type}")
        return None

    model_name_for_path = model_id.split("/")[-1]
    model_save_path = os.path.join(save_dir, model_name_for_path)

    if os.path.exists(model_save_path) and os.listdir(model_save_path):
        logger.info(f"âœ… ëª¨ë¸ {model_id}ì´(ê°€) ì´ë¯¸ {save_dir}ì— ì¡´ì¬")
        return model_save_path

    logger.debug(f"ğŸ› ï¸ ëª¨ë¸ {model_id}ë¥¼ {save_dir}ì— ë‹¤ìš´ë¡œë“œ ì‹œì‘")

    token = os.getenv("HF_TOKEN")
    if token is None:
        logger.warning("âš ï¸ Hugging Face API í† í°(HF_TOKEN)ì´ .envì— ì •ì˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # GPUì²´í¬
    load_kwargs = {}
    if torch.cuda.is_available():
        load_kwargs["torch_dtype"] = torch.float16
        logger.info("âœ… GPUë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ")
    else: 
        load_kwargs["torch_dtype"] = torch.float32
        logger.info("âœ… CPUë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ")
        
    if model_type == "casual_lm" and use_4bit:
        load_kwargs["quantization_config"] = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_use_double_quant=True,
            bnb_4bit_quant_type="nf4",
            bnb_4bit_compute_dtype=torch.float16
        )

    try:
        loader_cls = MODEL_LOADERS[model_type]
        model = loader_cls.from_pretrained(model_id, token=token, **load_kwargs)
        model.save_pretrained(model_save_path)
        logger.info(f"âœ… {model_type} ëª¨ë¸ '{model_id}' ì €ì¥ ì™„ë£Œ: {model_save_path}")
        return model_save_path

    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({model_id}): {e}")
        return None


def load_model(
        model_path: str,
        model_type: str = "diffusion_text2img",
        use_4bit: bool = False
    ):
    """
    ì €ì¥ëœ ëª¨ë¸ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.

    Args:
        model_path (str): ì‚¬ì „ì— ì €ì¥ëœ ëª¨ë¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        model_type (str): ëª¨ë¸ ìœ í˜• ("diffusion_text2img", "causal_lm", "encoder" ë“±)

    Returns:
        model: ë¡œë“œëœ ëª¨ë¸ ê°ì²´. ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
    """
    if not os.path.exists(model_path):
        logger.error(f"âŒ ëª¨ë¸ ê²½ë¡œ '{model_path}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None

    if model_type not in MODEL_LOADERS:
        logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” model_type: {model_type}")
        return None

    load_kwargs = {}
    if torch.cuda.is_available():
        load_kwargs["torch_dtype"] = torch.float16
        logger.info("âœ… GPUë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¡œë“œ")
    else: 
        load_kwargs["torch_dtype"] = torch.float32
        logger.info("âœ… CPUë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¡œë“œ")

    if model_type == "diffusion_text2img" or model_type == "diffusion_pipeline":
        load_kwargs["device_map"] = "balanced"
    elif model_type == "controlnet":
        load_kwargs["device_map"] = "cuda"
    elif model_type == "casual_lm" and use_4bit:
        load_kwargs["quantization_config"] = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_use_double_quant=True,
            bnb_4bit_quant_type="nf4",
            bnb_4bit_compute_dtype=torch.float16
        )
    else:
        load_kwargs["device_map"] = "auto"

    try:
        model = MODEL_LOADERS[model_type].from_pretrained(model_path, **load_kwargs)
        logger.info(f"âœ… ëª¨ë¸ì´ '{model_path}'ì—ì„œ ë¡œë“œ")
        return model
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def get_model_pipeline(
        model_id: str,
        model_type: str = "diffusion_text2img",
        use_ip_adapter: bool = True,
        ip_adapter_config: dict = None,
        lora_path: str = None,
        use_4bit: bool = False,
        save_dir: str = "./backend/models"
    ):
    """
    Hugging Face ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œí•˜ì—¬ íŒŒì´í”„ë¼ì¸ ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    í•„ìš”í•œ ê²½ìš° IP-Adapterë¥¼ ìë™ìœ¼ë¡œ ì£¼ì…í•©ë‹ˆë‹¤.

    ì´ í•¨ìˆ˜ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
    1. download_model()ì„ ì‚¬ìš©í•´ ì§€ì •ëœ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    2. load_model()ì„ í†µí•´ ë¡œì»¬ ëª¨ë¸ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    3. ì˜µì…˜ì— ë”°ë¼ IP-Adapterë¥¼ ì£¼ì…í•˜ì—¬ ëª¨ë¸ ê¸°ëŠ¥ì„ í™•ì¥í•©ë‹ˆë‹¤.

    Args:
        model_id (str): Hugging Face ëª¨ë¸ ID (ì˜ˆ: "stabilityai/stable-diffusion-xl-base-1.0").
        model_type (str, optional): ëª¨ë¸ ìœ í˜•. ê¸°ë³¸ê°’ì€ "diffusion_text2img".
            - ì§€ì›ë˜ëŠ” ê°’: "diffusion_text2img", "diffusion_pipeline", "vae", "controlnet" ë“±.
        use_ip_adapter (bool, optional): Trueì¼ ê²½ìš° IP-Adapterë¥¼ ë¡œë“œí•˜ê³  ì£¼ì…í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ True.
        ip_adapter_config (dict, optional): IP-Adapter ì„¤ì • ê°’.
            - ì˜ˆì‹œ:
                {
                    "repo_id": "h94/IP-Adapter",
                    "subfolder": "sdxl_models",
                    "weight_name": "ip-adapter_sdxl.bin",
                    "scale": 0.8
                }

    Returns:
        model_pipeline (object): ë¡œë“œëœ ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ê°ì²´.
            - IP-Adapterê°€ í™œì„±í™”ëœ ê²½ìš°, image_proj_model ì†ì„±ì„ í¬í•¨.
        None: ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë˜ëŠ” ë¡œë“œ ì‹¤íŒ¨ ì‹œ None ë°˜í™˜.

    Raises:
        Exception: IP-Adapter ë¡œë”© ì¤‘ ë°œìƒí•œ ì˜ˆì™¸ëŠ” warningìœ¼ë¡œ ë¡œê¹…ë©ë‹ˆë‹¤.
    """    
    model_path = download_model(model_id=model_id, model_type=model_type, save_dir=save_dir, use_4bit=use_4bit)
    
    if model_path is None:
        logger.error("âŒ ëª¨ë¸ ê²½ë¡œê°€ Noneì…ë‹ˆë‹¤. ë¡œë”©ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return None

    model_pipeline = load_model(model_path=model_path, model_type=model_type, use_4bit=use_4bit)

    # LoRA ì–´ëŒ‘í„° ì—°ê²°
    if lora_path and model_type == "casual_lm":
        try:
            model_pipeline = PeftModel.from_pretrained(model_pipeline, lora_path, local_files_only=True)
            model_pipeline.eval()
            logger.info(f"âœ… LLMìš© LoRA ì–´ëŒ‘í„° ì ìš© ì™„ë£Œ: {lora_path}")
        except Exception as e:
            logger.error(f"âŒ LoRA ì–´ëŒ‘í„° ë¡œë”© ì‹¤íŒ¨: {e}")
            return None

    # IP-Adapter ì£¼ì… (ì˜µì…˜)
    if use_ip_adapter and not hasattr(model_pipeline, "image_proj_model"):
        try:
            adapter_config = ip_adapter_config or {
                "repo_id": "h94/IP-Adapter",
                "subfolder": "sdxl_models",
                "weight_name": "ip-adapter_sdxl.bin",
                "scale": 0.7,
            }
            model_pipeline.load_ip_adapter(
                adapter_config["repo_id"],
                subfolder=adapter_config["subfolder"],
                weight_name=adapter_config["weight_name"],
            )
            model_pipeline.set_ip_adapter_scale(adapter_config["scale"])
            model_pipeline.enable_vae_tiling()
            model_pipeline.enable_attention_slicing()
            model_pipeline.enable_xformers_memory_efficient_attention()
            logger.info("âœ… IP-Adapter ì£¼ì… ë° ë©”ëª¨ë¦¬ ìµœì í™” ì˜µì…˜ ì ìš© ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"âš ï¸ IP-Adapter ì£¼ì… ë° ë©”ëª¨ë¦¬ ìµœì í™” ì˜µì…˜ ì ìš© ì‹¤íŒ¨: {e}")
            
    return model_pipeline


def get_vton_pipeline(
    pipeline_model: str = "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
    vae_model: str = "madebyollin/sdxl-vae-fp16-fix",
    controlnet_model: str = "diffusers/controlnet-depth-sdxl-1.0",
    midas_model: str = "lllyasviel/ControlNet",
    ip_adapter_config: dict = {
        "repo_id": "h94/IP-Adapter",
        "subfolder": "sdxl_models",
        "weight_name": "ip-adapter_sdxl.bin",
        "scale": 0.8
    },
    lora_config: dict = {
        "repo_id": "Norod78/weird-fashion-show-outfits-sdxl-lora",
        "weight_name": "sdxl-WeirdOutfit-Dreambooh.safetensors"
    },
):
    """
    Stable Diffusion ê¸°ë°˜ VTON íŒŒì´í”„ë¼ì¸ì„ í•œ ë²ˆì— ì¤€ë¹„í•©ë‹ˆë‹¤.
    (ë‹¤ìš´ë¡œë“œ + ë¡œë“œ + ì£¼ì… + IP-Adapter + LoRA ì ìš©)

    Args:
        pipeline_model (str): Inpainting íŒŒì´í”„ë¼ì¸ ëª¨ë¸ ID
        vae_model (str): VAE ëª¨ë¸ ID
        controlnet_model (str): ControlNet ëª¨ë¸ ID
        ip_adapter_config (dict): IP-Adapter ì„¤ì • {repo_id, subfolder, weight_name, scale}
        lora_config (dict): LoRA ì„¤ì • {repo_id, weight_name}
        save_dir (str): ëª¨ë¸ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ

    Returns:
        pipeline: GPU ë¡œë“œ ì™„ë£Œëœ ìµœì¢… íŒŒì´í”„ë¼ì¸
    """
    logger.debug("ğŸ› ï¸ vton íŒŒì´í”„ë¼ì¸ êµ¬ì„±ìš”ì†Œ ë‹¤ìš´ë¡œë“œ ë° ë¡œë”© ì‹œì‘")

    # ë‹¤ìš´ë¡œë“œ
    logger.debug("ğŸ› ï¸ íŒŒì´í”„ë¼ì¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘")
    pipeline_path = download_model(pipeline_model, model_type="diffusion_pipeline")
    vae_path = download_model(vae_model, model_type="vae")
    controlnet_path = download_model(controlnet_model, model_type="controlnet")

    if not all([pipeline_path, vae_path, controlnet_path]):
        logger.error("âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: í•˜ë‚˜ ì´ìƒì˜ ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•ŠìŒ")
        return None

    # ë¡œë“œ
    logger.debug("ğŸ› ï¸ íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì‹œì‘")
    vae = AutoencoderKL.from_pretrained(vae_path, torch_dtype=torch.float16)
    pipeline = AutoPipelineForInpainting.from_pretrained(
        pipeline_path,
        vae=vae,
        torch_dtype=torch.float16,
        use_safetensors=True
    ).to("cuda")
    controlnet = ControlNetModel.from_pretrained(controlnet_path, torch_dtype=torch.float16)

    # ì£¼ì…
    logger.debug("ğŸ› ï¸ êµ¬ì„±ìš”ì†Œ ì£¼ì… ì‹œì‘")
    pipeline.controlnet = controlnet

    # ë©”ëª¨ë¦¬ ìµœì í™”/ ì†ë„ í¬ìƒ
    # pipeline.enable_attention_slicing()
    pipeline.enable_vae_tiling()

    # IP-Adapter ì ìš©
    try:
        pipeline.load_ip_adapter(
            ip_adapter_config["repo_id"],
            subfolder=ip_adapter_config.get("subfolder", "sdxl_models"),
            weight_name=ip_adapter_config["weight_name"]
        )
        pipeline.set_ip_adapter_scale(ip_adapter_config.get("scale", 0.8))
        logger.info("âœ… IP-Adapter ì ìš© ì™„ë£Œ")
    except Exception as e:
        logger.warning(f"âš ï¸ IP-Adapter ì ìš© ì‹¤íŒ¨: {e}")

    # LoRA ì ìš©
    try:
        pipeline.load_lora_weights(
            lora_config["repo_id"],
            weight_name=lora_config["weight_name"]
        )
        logger.info("âœ… LoRA ì ìš© ì™„ë£Œ")
    except Exception as e:
        logger.warning(f"âš ï¸ LoRA ì ìš© ì‹¤íŒ¨: {e}")

    midas_detector = MidasDetector.from_pretrained(midas_model)

    return pipeline, midas_detector