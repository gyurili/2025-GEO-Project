import os
import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer
from diffusers import DiffusionPipeline
from utils.logger import get_logger

logger = get_logger(__name__)

def download_model(model_id: str, save_dir: str = "/home/ubuntu/2025-GEO-Project/backend/models")
    """
    Hugging Faceì—ì„œ Stable Diffusion XL (SDXL) ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì§€ì •ëœ ê²½ë¡œì— ì €ì¥í•©ë‹ˆë‹¤.
    CPU/GPU í™˜ê²½ì— ë”°ë¼ torch_dtypeì„ ì„¤ì •í•©ë‹ˆë‹¤.

    Args:
        model_id (str): Hugging Face ëª¨ë¸ ID (ì˜ˆ: "stabilityai/stable-diffusion-xl-base-1.0").
        save_dir (str, optional): ëª¨ë¸ì„ ì €ì¥í•  ê¸°ë³¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ.
                                  ê¸°ë³¸ê°’ì€ "/home/ubuntu/2025-GEO-Project/backend/models".

    Returns:
        str: ëª¨ë¸ì´ ì €ì¥ëœ ìµœì¢… ê²½ë¡œ. ë‹¤ìš´ë¡œë“œ ë˜ëŠ” ì €ì¥ì— ì‹¤íŒ¨í•˜ë©´ None ë°˜í™˜.
    """
    model_name_for_path = model_id.split("/")[-1]
    model_save_path = os.path.join(save_dir, model_name_for_path)

    if os.path.exists(model_save_path) and os.listdir(model_save_path):
        logger.info(f"âœ… ëª¨ë¸ {model_id}ì´(ê°€) ì´ë¯¸ {save_dir}ì— ì¡´ì¬í•©ë‹ˆë‹¤.")
        return model_save_path

    logger.debug(f"ğŸ› ï¸ ëª¨ë¸ {model_id}ë¥¼ {save_dir}ì— ë‹¤ìš´ë¡œë“œ")

    # GPUì²´í¬
    load_kwargs = {}
    if torch.cuda.is_available():
        load_kwargs["torch_dtype"] = torch.float16
        logger.info("âœ… GPUë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.")
    else: 
        load_kwargs["torch_dtype"] = torch.float32
        logger.info("âœ… CPUë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.")
    load_kwargs["device_map"] = "auto"

    try:
        pipeline = DiffusionPipeline.from_pretrained(
            model_id,
            **load_kwargs
        )

        pipeline.save_pretrained(model_save_path)
        logger.info(f"âœ… ëª¨ë¸ '{model_id}'ì´(ê°€) '{model_save_path}'ì— ì €ì¥ë¨")
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ '{model_id}' ë‹¤ìš´ë¡œë“œ ë° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None
        
# # ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ ë° ì €ì¥
# model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")
# tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")

# # ëª¨ë¸ ì €ì¥
# model.save_pretrained(MODEL_DIR)
# tokenizer.save_pretrained(MODEL_DIR)

# print(f"ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ê°€ {MODEL_DIR}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# load_model.py

# from transformers import AutoModelForSequenceClassification, AutoTokenizer

# # ê³µìš© í´ë” ê²½ë¡œ
# MODEL_DIR = "/home/shared/models/distilbert-base-uncased"

# # ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
# model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)
# tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)

# print("ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ê³µìš© í´ë”ì—ì„œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")