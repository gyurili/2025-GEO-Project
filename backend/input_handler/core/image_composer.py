from google import genai
from google.genai import types
from PIL import Image
from io import BytesIO
from openai import OpenAI
import base64
import os
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional
import uuid
from dotenv import load_dotenv

# ë¡œê±° ì„í¬íŠ¸ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent.parent.parent))
from utils.logger import get_logger

# ë¡œê±° ì„¤ì •
logger = get_logger(__name__)

class ImageComposer:
    """ì´ë¯¸ì§€ í•©ì„± í´ë˜ìŠ¤"""
    
    def __init__(self):
        logger.debug("ğŸ› ï¸ ImageComposer ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™” ì‹œì‘")
        
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ .env íŒŒì¼ ë¡œë“œ
        project_root = Path(__file__).parent.parent.parent.parent
        env_path = project_root / ".env"
        
        if env_path.exists():
            load_dotenv(env_path)
            logger.debug(f"ğŸ› ï¸ .env íŒŒì¼ ë¡œë“œ: {env_path}")
        else:
            logger.warning(f"âš ï¸ .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {env_path}")
        
        # API í‚¤ ì„¤ì •
        self.gemini_api_key = os.getenv("GEMINI_API_KEY", "")
        self.openai_api_key = os.getenv("OPENAI_API_KEY", "")
        
        # API í‚¤ í™•ì¸ (ë³´ì•ˆìƒ ê¸¸ì´ë§Œ í‘œì‹œ)
        if self.gemini_api_key:
            logger.debug(f"ğŸ› ï¸ Gemini API í‚¤ ë¡œë“œë¨: {len(self.gemini_api_key)}ì")
        else:
            logger.warning("âš ï¸ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
        if self.openai_api_key:
            logger.debug(f"ğŸ› ï¸ OpenAI API í‚¤ ë¡œë“œë¨: {len(self.openai_api_key)}ì")
        else:
            logger.warning("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        if not self.gemini_api_key or not self.openai_api_key:
            logger.error("âŒ í•„ìˆ˜ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            self.openai_client = OpenAI(api_key=self.openai_api_key) if self.openai_api_key else None
            self.gemini_client = genai.Client(api_key=self.gemini_api_key) if self.gemini_api_key else None
            logger.info("âœ… ImageComposer í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.openai_client = None
            self.gemini_client = None
    
    def _load_image_safely(self, image_path: str, image_type: str, target_mode: str = 'RGB') -> Optional[Image.Image]:
        """
        ì´ë¯¸ì§€ë¥¼ ì•ˆì „í•˜ê²Œ ë¡œë“œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            image_type: ì´ë¯¸ì§€ íƒ€ì… (ë¡œê¹…ìš©) - 'user', 'target', 'mask'
            target_mode: ë³€í™˜í•  ì´ë¯¸ì§€ ëª¨ë“œ (ê¸°ë³¸ê°’: 'RGB')
        
        Returns:
            PIL Image ê°ì²´ ë˜ëŠ” None
        """
        logger.debug(f"ğŸ› ï¸ {image_type} ì´ë¯¸ì§€ ë¡œë“œ ì‹œì‘: {image_path}")
        
        if not os.path.exists(image_path):
            logger.error(f"âŒ {image_type} ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {image_path}")
            return None
        
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = Image.open(image_path)
            original_mode = image.mode
            
            # ì§€ì •ëœ ëª¨ë“œë¡œ ë³€í™˜
            if image.mode != target_mode:
                image = image.convert(target_mode)
                logger.debug(f"ğŸ› ï¸ {image_type} ì´ë¯¸ì§€ ëª¨ë“œ ë³€í™˜: {original_mode} â†’ {target_mode}")
            
            logger.debug(f"ğŸ› ï¸ {image_type} ì´ë¯¸ì§€ ë¡œë“œ ì„±ê³µ: {image.size}, ëª¨ë“œ: {image.mode}")
            return image
            
        except Exception as e:
            logger.error(f"âŒ {image_type} ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def convert_korean_request_to_prompt(self, korean_request: str, num_images: int, generation_type: str, num_products: int = 1) -> Optional[str]:
        """í•œê¸€ ìš”ì²­ì‚¬í•­ì„ ì˜ë¬¸ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜ (ë‹¤ì¤‘ ìƒí’ˆ ì´ë¯¸ì§€ ì§€ì›)"""
        logger.debug(f"ğŸ› ï¸ í”„ë¡¬í”„íŠ¸ ë³€í™˜: {generation_type}, {num_products}ê°œ ìƒí’ˆ, {num_images}ê°œ ì´ë¯¸ì§€")
        
        if not self.openai_client:
            logger.error("âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            return None
        
        # âœ… ì´ë¯¸ì§€ ì°¸ì¡° ë²ˆí˜¸ ìƒì„± (ì‹¤ì œ ì „ë‹¬ë˜ëŠ” ì´ë¯¸ì§€ ìˆœì„œì™€ ì¼ì¹˜)
        if num_products > 1:
            product_refs = ", ".join([f"(#{i+1})" for i in range(num_products)])
            target_ref = f"(#{num_products + 1})"
            mask_ref = f"(#{num_products + 2})" if num_images > num_products + 1 else ""
        else:
            product_refs = "(#1)"
            target_ref = "(#2)"
            mask_ref = "(#3)" if num_images > 2 else ""
        
        logger.debug(f"ğŸ› ï¸ ì°¸ì¡° ë²ˆí˜¸ - ìƒí’ˆ: {product_refs}, íƒ€ê²Ÿ: {target_ref}, ë§ˆìŠ¤í¬: {mask_ref}")
        
        if generation_type == "model":
            system_prompt = f"""
    ë‹¹ì‹ ì€ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì‚¬ìš©ìì˜ í•œê¸€ ìš”ì²­ì‚¬í•­ì„ ëª¨ë¸ê³¼ ìƒí’ˆ í•©ì„±ì„ ìœ„í•œ ì˜ë¬¸ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

    ê·œì¹™:
    1. ìì—°ìŠ¤ëŸ½ê³  í˜„ì‹¤ì ì¸ ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”
    2. ìƒí’ˆ ì´ë¯¸ì§€ ì°¸ì¡°: {product_refs}, ëª¨ë¸ ì´ë¯¸ì§€: {target_ref}{', ë§ˆìŠ¤í¬: ' + mask_ref if mask_ref else ''}
    3. í…ìŠ¤íŠ¸ë‚˜ ê¸€ìê°€ í¬í•¨ë˜ì§€ ì•Šë„ë¡ ì§€ì‹œí•˜ì„¸ìš”
    4. "Generate a natural-looking image"ë¡œ ì‹œì‘í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤

    ë‹¤ì¤‘ ìƒí’ˆê³¼ ëª¨ë¸ í•©ì„±:
    - ëª¨ë¸ì˜ ì‹ ì²´ ë¹„ìœ¨ê³¼ í¬ì¦ˆë¥¼ ìœ ì§€í•˜ë„ë¡ ì§€ì‹œí•˜ì„¸ìš”
    - ì—¬ëŸ¬ ìƒí’ˆì´ ìˆëŠ” ê²½ìš° ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜í•˜ë„ë¡ ì§€ì‹œí•˜ì„¸ìš”
    - ì˜ìƒì„ ì…íˆëŠ” ê²½ìš° "naturally wearing"ê³¼ ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”
    - ë¬¼ê±´ì„ ë“¤ê³  ìˆëŠ” ê²½ìš° "holding" ë˜ëŠ” "using"ê³¼ ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”

    ì˜ˆì‹œ:
    - ë‹¨ì¼ ìƒí’ˆ: "Generate a natural-looking image where the model from {target_ref} maintains their body proportions and pose, but is naturally wearing the product from {product_refs}."
    - ë‹¤ì¤‘ ìƒí’ˆ: "Generate a natural-looking image where the model from {target_ref} maintains their body proportions and pose, naturally interacting with all products from {product_refs} in a cohesive and realistic way."
            """
        else:  # background
            system_prompt = f"""
    ë‹¹ì‹ ì€ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì‚¬ìš©ìì˜ í•œê¸€ ìš”ì²­ì‚¬í•­ì„ ìƒí’ˆ ë°°ê²½ í•©ì„±ì„ ìœ„í•œ ì˜ë¬¸ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

    ê·œì¹™:
    1. ìì—°ìŠ¤ëŸ½ê³  í˜„ì‹¤ì ì¸ ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”
    2. ìƒí’ˆ ì´ë¯¸ì§€ ì°¸ì¡°: {product_refs}, ë°°ê²½ ì´ë¯¸ì§€: {target_ref}
    3. í…ìŠ¤íŠ¸ë‚˜ ê¸€ìê°€ í¬í•¨ë˜ì§€ ì•Šë„ë¡ ì§€ì‹œí•˜ì„¸ìš”
    4. "Generate a natural-looking image"ë¡œ ì‹œì‘í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤

    ë‹¤ì¤‘ ìƒí’ˆê³¼ ë°°ê²½ í•©ì„±:
    - ì—¬ëŸ¬ ìƒí’ˆì´ ìˆëŠ” ê²½ìš° ë°°ê²½ì— ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜í•˜ë„ë¡ ì§€ì‹œí•˜ì„¸ìš”
    - "placed in", "positioned on", "arranged in" ë“±ì˜ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”
    - ìƒí’ˆë“¤ì˜ ì›ë˜ í˜•íƒœì™€ íŠ¹ì„±ì„ ìœ ì§€í•˜ë„ë¡ ì§€ì‹œí•˜ì„¸ìš”

    ì˜ˆì‹œ:
    - ë‹¨ì¼ ìƒí’ˆ: "Generate a natural-looking image of the product from {product_refs} elegantly placed in the setting from {target_ref}."
    - ë‹¤ì¤‘ ìƒí’ˆ: "Generate a natural-looking image with all products from {product_refs} beautifully arranged in the setting from {target_ref}, maintaining their individual characteristics."
            """
        
        try:
            logger.debug("ğŸ› ï¸ OpenAI API í˜¸ì¶œ ì‹œì‘")
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": korean_request or "ìì—°ìŠ¤ëŸ½ê²Œ í•©ì„±í•´ì£¼ì„¸ìš”"}
                ],
                max_tokens=300,  # ë‹¤ì¤‘ ìƒí’ˆìš©ìœ¼ë¡œ í† í° ìˆ˜ ì¦ê°€
                temperature=0.7
            )
            
            prompt = response.choices[0].message.content.strip()
            logger.info(f"âœ… í”„ë¡¬í”„íŠ¸ ë³€í™˜ ì™„ë£Œ: {len(prompt)}ì")
            return prompt
            
        except Exception as e:
            logger.error(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def analyze_combination_intent(self, korean_request: str, num_products: int) -> Dict[str, Any]:
        """ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ì„ ë¶„ì„í•˜ì—¬ ìƒí’ˆ ì¡°í•© ì˜ë„ íŒŒì•…"""
        logger.debug(f"ğŸ› ï¸ ì¡°í•© ì˜ë„ ë¶„ì„ ì‹œì‘: {num_products}ê°œ ìƒí’ˆ")
        
        if num_products <= 1:
            return {
                'combine_products': False,
                'description': 'ë‹¨ì¼ ìƒí’ˆ'
            }
        
        if not korean_request or korean_request.strip() == "":
            return {
                'combine_products': False,
                'description': 'ìš”ì²­ì‚¬í•­ ì—†ìŒ - ê°œë³„ ì°©ìš©'
            }
        
        if not self.openai_client:
            logger.error("âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            return {
                'combine_products': False,
                'description': 'ê¸°ë³¸ê°’ - ê°œë³„ ì°©ìš©'
            }
        
        system_prompt = f"""
ë‹¹ì‹ ì€ íŒ¨ì…˜ ì˜ìƒ ì¡°í•© ìš”ì²­ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ {num_products}ê°œì˜ ìƒí’ˆì— ëŒ€í•´ ìš”ì²­í•œ ë‚´ìš©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

íŒë‹¨ ê¸°ì¤€:
1. "combine_products": true - ì—¬ëŸ¬ ìƒí’ˆì„ ë™ì‹œì— ì°©ìš©í•˜ë¼ëŠ” ì˜ë„ê°€ ëª…í™•í•œ ê²½ìš°
   ì˜ˆì‹œ: 
   - "ë°”ì§€ì™€ í‹°ì…”ì¸ ë¥¼ ì…ê³  ìˆëŠ”"
   - "ìƒì˜ì™€ í•˜ì˜ë¥¼ í•¨ê»˜"
   - "ì„¸íŠ¸ë¡œ ì°©ìš©í•œ"
   - "ëª¨ë“  ì˜·ì„ ì…ì€"
   - ë³µìˆ˜ì˜ ì˜ë¥˜ ì•„ì´í…œì„ ë™ì‹œì— ì–¸ê¸‰

2. "combine_products": false - ê°œë³„ ì°©ìš©ì„ ì›í•˜ê±°ë‚˜ ëª…í™•í•˜ì§€ ì•Šì€ ê²½ìš°
   ì˜ˆì‹œ:
   - "ë°”ì§€ë¥¼ ì…ì€ ëª¨ë¸" (ë‹¨ì¼ ì•„ì´í…œë§Œ ì–¸ê¸‰)
   - "ìì—°ìŠ¤ëŸ½ê²Œ" (êµ¬ì²´ì  ì–¸ê¸‰ ì—†ìŒ)
   - ë¹ˆ ë¬¸ìì—´ ë˜ëŠ” ì¼ë°˜ì ì¸ ìš”ì²­

ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ í•´ì£¼ì„¸ìš”:
{{
    "combine_products": true ë˜ëŠ” false,
    "reasoning": "íŒë‹¨ ê·¼ê±°"
}}
"""
    
        try:
            logger.debug("ğŸ› ï¸ OpenAI API í˜¸ì¶œë¡œ ì¡°í•© ì˜ë„ ë¶„ì„")
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": korean_request}
                ],
                max_tokens=150,
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            
            import json
            result = json.loads(response.choices[0].message.content)
            combine_products = result.get('combine_products', False)
            reasoning = result.get('reasoning', '')
            
            logger.info(f"âœ… ì¡°í•© ì˜ë„ ë¶„ì„: {'ë™ì‹œ ì°©ìš©' if combine_products else 'ê°œë³„ ì°©ìš©'} - {reasoning}")
            
            return {
                'combine_products': combine_products,
                'description': f"{'ë™ì‹œ ì°©ìš©' if combine_products else 'ê°œë³„ ì°©ìš©'} - {reasoning}"
            }
            
        except Exception as e:
            logger.error(f"âŒ ì¡°í•© ì˜ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'combine_products': False,
                'description': 'ë¶„ì„ ì‹¤íŒ¨ - ê°œë³„ ì°©ìš© (ê¸°ë³¸ê°’)'
            }
    
    def generate_image_with_gemini(self, prompt: str, images: List[Image.Image]) -> Optional[Image.Image]:
        """Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„±"""
        logger.debug(f"ğŸ› ï¸ Gemini ì´ë¯¸ì§€ ìƒì„± ì‹œì‘: {len(images)}ê°œ ì´ë¯¸ì§€")
        
        if not self.gemini_client:
            logger.error("âŒ Gemini í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            return None
        
        try:
            # ì´ë¯¸ì§€ ì •ë³´ ë¡œê¹…
            for i, img in enumerate(images):
                logger.debug(f"ğŸ› ï¸ ì´ë¯¸ì§€ {i+1}: {img.size}, ëª¨ë“œ: {img.mode}")
            
            # í”„ë¡¬í”„íŠ¸ì™€ ì´ë¯¸ì§€ë“¤ì„ í•¨ê»˜ ì „ë‹¬
            contents = [prompt] + images
            logger.debug(f"ğŸ› ï¸ Gemini API í˜¸ì¶œ: í”„ë¡¬í”„íŠ¸ ê¸¸ì´={len(prompt)}, ì´ë¯¸ì§€ ìˆ˜={len(images)}")
            
            response = self.gemini_client.models.generate_content(
                model="gemini-2.0-flash-preview-image-generation",
                contents=contents,
                config=types.GenerateContentConfig(
                    response_modalities=['TEXT', 'IMAGE']
                )
            )
            
            # ê²°ê³¼ ì´ë¯¸ì§€ ì¶”ì¶œ ë¶€ë¶„ ìˆ˜ì •
            for part in response.candidates[0].content.parts:
                if part.text is not None:
                    logger.debug(f"ğŸ› ï¸ Gemini ì‘ë‹µ í…ìŠ¤íŠ¸: {part.text}")
                elif part.inline_data is not None:
                    try:
                        # ğŸ” ì¶”ê°€ ë””ë²„ê¹…
                        logger.debug(f"ğŸ› ï¸ inline_data íƒ€ì…: {type(part.inline_data)}")
                        logger.debug(f"ğŸ› ï¸ inline_data.data íƒ€ì…: {type(part.inline_data.data)}")
                        logger.debug(f"ğŸ› ï¸ inline_data.data ê¸¸ì´: {len(part.inline_data.data)}")
                        
                        # bytesë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (base64 ë””ì½”ë”©ì„ ìœ„í•´)
                        if isinstance(part.inline_data.data, bytes):
                            base64_string = part.inline_data.data.decode('utf-8')
                        else:
                            base64_string = part.inline_data.data
                            
                        # base64 ë””ì½”ë”©
                        image_data = base64.b64decode(base64_string)
                        logger.debug(f"ğŸ› ï¸ ë””ì½”ë”©ëœ ì´ë¯¸ì§€ ë°ì´í„° ê¸¸ì´: {len(image_data)}")
                        
                        # BytesIO ê°ì²´ ìƒì„± ë° ì´ë¯¸ì§€ ë¡œë“œ
                        image_bytes = BytesIO(image_data)
                        image_bytes.seek(0)
                        
                        result_image = Image.open(image_bytes)
                        logger.info(f"âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {result_image.size}")
                        return result_image
                        
                    except Exception as e:
                        logger.error(f"âŒ ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
                        logger.debug(f"ğŸ› ï¸ ì´ë¯¸ì§€ ë°ì´í„° ì²˜ìŒ 100ë°”ì´íŠ¸: {part.inline_data.data[:100]}")
                        return None
                        
                    except Exception as e:
                        logger.error(f"âŒ ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
                        logger.debug(f"ğŸ› ï¸ ì´ë¯¸ì§€ ë°ì´í„° ì²˜ìŒ 100ë°”ì´íŠ¸: {part.inline_data.data[:100]}")
                        return None
            
            logger.warning("âš ï¸ ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return None
            
        except Exception as e:
            logger.error(f"âŒ Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def compose_images(self, composition_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        ì´ë¯¸ì§€ í•©ì„± ë©”ì¸ í•¨ìˆ˜
        - í•­ìƒ ì„ íƒí•œ ìƒí’ˆ ìˆ˜ë§Œí¼ ê²°ê³¼ë¬¼ ìƒì„±
        - ìš”ì²­ì‚¬í•­ì— ë”°ë¼ ê° ê²°ê³¼ë¬¼ì˜ ì¡°í•© ë°©ì‹ ê²°ì •
        """
        logger.debug("ğŸ› ï¸ ì´ë¯¸ì§€ í•©ì„± í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
        try:
            user_images_data = composition_data.get('user_images', [])
            target_image_data = composition_data.get('target_image')
            mask_image_data = composition_data.get('mask_image')
            generation_options = composition_data.get('generation_options', {})
            generation_type = generation_options.get('type', 'background')
            
            num_products = len(user_images_data)
            logger.debug(f"ğŸ› ï¸ í•©ì„± íƒ€ì…: {generation_type}, ìƒí’ˆ ìˆ˜: {num_products}")

            # ì¡°í•© ì˜ë„ ë¶„ì„
            combination_info = self.analyze_combination_intent(
                generation_options.get('custom_prompt', ''), 
                num_products
            )
            
            logger.info(f"ğŸ¯ ì¡°í•© ì „ëµ: {combination_info['description']}")
            
            # í•­ìƒ ìƒí’ˆ ìˆ˜ë§Œí¼ ê²°ê³¼ ìƒì„±
            results = []
            project_root = Path(__file__).parent.parent.parent.parent
            result_dir = project_root / "backend" / "data" / "output"
            result_dir.mkdir(parents=True, exist_ok=True)
            
            for i in range(num_products):
                logger.debug(f"ğŸ› ï¸ ê²°ê³¼ë¬¼ {i+1}/{num_products} ìƒì„± ì‹œì‘")
                
                if combination_info['combine_products']:
                    # ëª¨ë“  ìƒí’ˆì„ í•¨ê»˜ ì°©ìš©í•œ ì´ë¯¸ì§€ ìƒì„±
                    result = self._generate_combined_image_for_result(
                        user_images_data, target_image_data, mask_image_data,
                        generation_options, generation_type, i + 1
                    )
                else:
                    # ê°œë³„ ìƒí’ˆë§Œ ì°©ìš©í•œ ì´ë¯¸ì§€ ìƒì„±
                    result = self._generate_individual_image_for_result(
                        user_images_data[i], target_image_data, mask_image_data,
                        generation_options, generation_type, i + 1
                    )
                
                if result:
                    results.append(result)
                    logger.info(f"âœ… ê²°ê³¼ë¬¼ {i+1} ìƒì„± ì™„ë£Œ")
                else:
                    logger.error(f"âŒ ê²°ê³¼ë¬¼ {i+1} ìƒì„± ì‹¤íŒ¨")
            
            if not results:
                logger.error("âŒ ëª¨ë“  ê²°ê³¼ë¬¼ ìƒì„± ì‹¤íŒ¨")
                return None
            
            return {
                'success': True,
                'results': results,
                'generation_type': generation_type,
                'total_images': len(results),
                'product_images_count': num_products,
                'combination_strategy': combination_info['description']
            }
                
        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ í•©ì„± í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")
            return None

    def _generate_combined_image_for_result(self, user_images_data, target_image_data, mask_image_data, 
                                      generation_options, generation_type, result_index) -> Optional[Dict[str, Any]]:
        """ëª¨ë“  ìƒí’ˆì„ í•¨ê»˜ ì°©ìš©í•œ ì´ë¯¸ì§€ ìƒì„± (ë‹¨ì¼ ê²°ê³¼ë¬¼ìš©)"""
        logger.debug(f"ğŸ› ï¸ í†µí•© ì°©ìš© ì´ë¯¸ì§€ ìƒì„±: ê²°ê³¼ë¬¼ {result_index}")
        
        images = []
        
        # âœ… ëª¨ë“  ìƒí’ˆ ì´ë¯¸ì§€ë¥¼ ìˆœì„œëŒ€ë¡œ ë¡œë“œ
        logger.debug(f"ğŸ› ï¸ ëª¨ë“  ìƒí’ˆ ì´ë¯¸ì§€ ë¡œë“œ ì‹œì‘: {len(user_images_data)}ê°œ")
        for i, user_image_data in enumerate(user_images_data):
            user_image = self._load_image_safely(user_image_data['path'], f'ìƒí’ˆ_{i+1}', 'RGB')
            if not user_image:
                logger.error(f"âŒ ìƒí’ˆ ì´ë¯¸ì§€ {i+1} ë¡œë“œ ì‹¤íŒ¨: {user_image_data['path']}")
                return None
            images.append(user_image)
            logger.debug(f"âœ… ìƒí’ˆ ì´ë¯¸ì§€ {i+1} ì¶”ê°€: {user_image.size}")
        
        # íƒ€ê²Ÿ ì´ë¯¸ì§€ ì²˜ë¦¬
        if generation_type == 'model':
            if not target_image_data or 'path' not in target_image_data:
                logger.error("âŒ ëª¨ë¸ ì´ë¯¸ì§€ ì •ë³´ ì—†ìŒ")
                return None
            model_image = self._load_image_safely(target_image_data['path'], 'model', 'RGB')
            if not model_image:
                return None
            images.append(model_image)
            logger.debug(f"âœ… ëª¨ë¸ ì´ë¯¸ì§€ ì¶”ê°€: {model_image.size}")
            
            # ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ (ì„ íƒ)
            if mask_image_data and 'path' in mask_image_data:
                mask_image = self._load_image_safely(mask_image_data['path'], 'mask', 'L')
                if mask_image:
                    images.append(mask_image)
                    logger.debug(f"âœ… ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ì¶”ê°€: {mask_image.size}")
        
        # âœ… ì‹¤ì œ ì´ë¯¸ì§€ ìˆœì„œì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±
        total_images = len(images)
        logger.debug(f"ğŸ› ï¸ ì´ ì „ë‹¬í•  ì´ë¯¸ì§€ ìˆ˜: {total_images}")
        logger.debug(f"ğŸ› ï¸ ì´ë¯¸ì§€ êµ¬ì„±: ìƒí’ˆ {len(user_images_data)}ê°œ + ëª¨ë¸/ë°°ê²½ 1ê°œ" + 
                    (f" + ë§ˆìŠ¤í¬ 1ê°œ" if generation_type == 'model' and mask_image_data else ""))
        
        # í†µí•© ì°©ìš©ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
        if generation_type == 'model':
            prompt = self.convert_korean_request_to_prompt(
                generation_options.get('custom_prompt', ''),
                num_images=total_images,
                generation_type='model',
                num_products=len(user_images_data)
            )
        else:  # background
            base_prompt = target_image_data.get('prompt', '')
            prompt = self.convert_korean_request_to_prompt(
                f"ë‹¤ìŒ ë°°ê²½ì— ëª¨ë“  ìƒí’ˆì„ ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜í•´ì£¼ì„¸ìš”: {base_prompt}",
                num_images=total_images,
                generation_type='background',
                num_products=len(user_images_data)
            )
        
        if not prompt:
            logger.error("âŒ í”„ë¡¬í”„íŠ¸ ë³€í™˜ ì‹¤íŒ¨")
            return None
        
        logger.debug(f"ğŸ› ï¸ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸: {prompt}")
        
        # âœ… ì´ë¯¸ì§€ ìƒì„± (ëª¨ë“  ìƒí’ˆ ì´ë¯¸ì§€ + ëª¨ë¸/ë°°ê²½ ì´ë¯¸ì§€ ì „ë‹¬)
        result_image = self.generate_image_with_gemini(prompt, images)
        if not result_image:
            logger.error("âŒ Gemini ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")
            return None
        
        # ê²°ê³¼ ì €ì¥
        project_root = Path(__file__).parent.parent.parent.parent
        result_dir = project_root / "backend" / "data" / "output"
        result_filename = f"composed_{generation_type}_combined_{result_index}_{uuid.uuid4().hex[:8]}.png"
        result_path = result_dir / result_filename
        result_image.save(result_path)
        
        relative_path = os.path.relpath(result_path, project_root)
        logger.info(f"âœ… í†µí•© ì°©ìš© ì´ë¯¸ì§€ ì €ì¥: {relative_path}")
        
        return {
            'result_image_path': relative_path,
            'prompt_used': prompt,
            'result_index': result_index,
            'combination_type': 'ëª¨ë“  ìƒí’ˆ ë™ì‹œ ì°©ìš©',
            'images_used': f"ìƒí’ˆ {len(user_images_data)}ê°œ + ëª¨ë¸/ë°°ê²½ 1ê°œ"
        }

    def _generate_individual_image_for_result(self, user_image_data, target_image_data, mask_image_data,
                                        generation_options, generation_type, result_index) -> Optional[Dict[str, Any]]:
        """ê°œë³„ ìƒí’ˆë§Œ ì°©ìš©í•œ ì´ë¯¸ì§€ ìƒì„± (ë‹¨ì¼ ê²°ê³¼ë¬¼ìš©)"""
        logger.debug(f"ğŸ› ï¸ ê°œë³„ ì°©ìš© ì´ë¯¸ì§€ ìƒì„±: ê²°ê³¼ë¬¼ {result_index}")
        
        images = []
        
        # âœ… í˜„ì¬ ìƒí’ˆ ì´ë¯¸ì§€ë§Œ ë¡œë“œ
        logger.debug(f"ğŸ› ï¸ ìƒí’ˆ {result_index} ì´ë¯¸ì§€ ë¡œë“œ: {user_image_data['path']}")
        user_image = self._load_image_safely(user_image_data['path'], f'ìƒí’ˆ_{result_index}', 'RGB')
        if not user_image:
            logger.error(f"âŒ ìƒí’ˆ {result_index} ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {user_image_data['path']}")
            return None
        images.append(user_image)
        logger.debug(f"âœ… ìƒí’ˆ {result_index} ì´ë¯¸ì§€ ì¶”ê°€: {user_image.size}")
        
        # íƒ€ê²Ÿ ì´ë¯¸ì§€ ì²˜ë¦¬
        if generation_type == 'model':
            if not target_image_data or 'path' not in target_image_data:
                logger.error("âŒ ëª¨ë¸ ì´ë¯¸ì§€ ì •ë³´ ì—†ìŒ")
                return None
            model_image = self._load_image_safely(target_image_data['path'], 'model', 'RGB')
            if not model_image:
                return None
            images.append(model_image)
            logger.debug(f"âœ… ëª¨ë¸ ì´ë¯¸ì§€ ì¶”ê°€: {model_image.size}")
            
            # ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ (ì„ íƒ)
            if mask_image_data and 'path' in mask_image_data:
                mask_image = self._load_image_safely(mask_image_data['path'], 'mask', 'L')
                if mask_image:
                    images.append(mask_image)
                    logger.debug(f"âœ… ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ì¶”ê°€: {mask_image.size}")
        
        # âœ… ì‹¤ì œ ì´ë¯¸ì§€ ìˆœì„œì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±
        total_images = len(images)
        logger.debug(f"ğŸ› ï¸ ì´ ì „ë‹¬í•  ì´ë¯¸ì§€ ìˆ˜: {total_images}")
        logger.debug(f"ğŸ› ï¸ ì´ë¯¸ì§€ êµ¬ì„±: ìƒí’ˆ 1ê°œ + ëª¨ë¸/ë°°ê²½ 1ê°œ" + 
                    (f" + ë§ˆìŠ¤í¬ 1ê°œ" if generation_type == 'model' and mask_image_data else ""))
        
        # ê°œë³„ ì°©ìš©ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
        if generation_type == 'model':
            prompt = self.convert_korean_request_to_prompt(
                generation_options.get('custom_prompt', ''),
                num_images=total_images,
                generation_type='model',
                num_products=1  # âœ… ê°œë³„ ìƒì„±ì´ë¯€ë¡œ 1ê°œ
            )
        else:  # background
            base_prompt = target_image_data.get('prompt', '')
            prompt = self.convert_korean_request_to_prompt(
                f"ë‹¤ìŒ ë°°ê²½ì— ìƒí’ˆì„ ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜í•´ì£¼ì„¸ìš”: {base_prompt}",
                num_images=total_images,
                generation_type='background',
                num_products=1
            )
        
        if not prompt:
            logger.error(f"âŒ ìƒí’ˆ {result_index} í”„ë¡¬í”„íŠ¸ ë³€í™˜ ì‹¤íŒ¨")
            return None
        
        logger.debug(f"ğŸ› ï¸ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸: {prompt}")
        
        # âœ… ì´ë¯¸ì§€ ìƒì„± (ë‹¨ì¼ ìƒí’ˆ ì´ë¯¸ì§€ + ëª¨ë¸/ë°°ê²½ ì´ë¯¸ì§€ ì „ë‹¬)
        result_image = self.generate_image_with_gemini(prompt, images)
        if not result_image:
            logger.error(f"âŒ ìƒí’ˆ {result_index} Gemini ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")
            return None
        
        # ê²°ê³¼ ì €ì¥
        project_root = Path(__file__).parent.parent.parent.parent
        result_dir = project_root / "backend" / "data" / "output"
        result_filename = f"composed_{generation_type}_individual_{result_index}_{uuid.uuid4().hex[:8]}.png"
        result_path = result_dir / result_filename
        result_image.save(result_path)
        
        relative_path = os.path.relpath(result_path, project_root)
        logger.info(f"âœ… ê°œë³„ ì°©ìš© ì´ë¯¸ì§€ ì €ì¥: {relative_path}")
        
        return {
            'result_image_path': relative_path,
            'prompt_used': prompt,
            'result_index': result_index,
            'combination_type': f'ìƒí’ˆ {result_index} ê°œë³„ ì°©ìš©',
            'product_name': user_image_data.get('relative_path', f'ìƒí’ˆ_{result_index}'),
            'images_used': f"ìƒí’ˆ 1ê°œ + ëª¨ë¸/ë°°ê²½ 1ê°œ"
        }
