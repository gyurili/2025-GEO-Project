import threading
import time
from backend.competitor_analysis.core.crawler import crawl_reviews_by_category
from backend.competitor_analysis.core.differentiator import summarize_competitor_reviews
from backend.competitor_analysis.core.competitor_db import insert_review_summary
from backend.competitor_analysis.core.crawl_signal_server import poll_and_process_signal
from utils.logger import get_logger

logger = get_logger(__name__)

def auto_crawl_loop(
    db_config,
    openai_api_key,
    category_list,
    interval=1800  # 30ë¶„ë§ˆë‹¤ (ì´ˆ ë‹¨ìœ„)
):
    """
    ìœ ëª… ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ìë™ í¬ë¡¤ë§/ìš”ì•½/DB ì €ì¥
    """
    logger.info(f"âœ… ìë™ í¬ë¡¤ë§ ë£¨í”„ ì‹œì‘ (ì£¼ê¸°: {interval}s)")
    while True:
        for category in category_list:
            try:
                logger.info(f"âœ… ìë™ í¬ë¡¤ë§ ì‹œë„: {category}")
                reviews = crawl_reviews_by_category(category, max_products=3, max_reviews_per_product=10)
                if not reviews:
                    logger.warning(f"âš ï¸ ë¦¬ë·° ì—†ìŒ: {category}")
                    continue
                summary = summarize_competitor_reviews(reviews, openai_api_key)
                insert_review_summary(
                    host=db_config["host"],
                    user=db_config["user"],
                    password=db_config["password"],
                    db=db_config["db"],
                    category=category,
                    review_summary=summary,
                    num_reviews=len(reviews)
                )
                logger.info(f"âœ… ìë™ í¬ë¡¤ë§+ìš”ì•½+ì €ì¥ ì™„ë£Œ: {category}")
            except Exception as e:
                logger.error(f"âŒ ìë™ í¬ë¡¤ë§/ìš”ì•½/ì €ì¥ ì‹¤íŒ¨: {e}")
        logger.info(f"ğŸ› ï¸ ëª¨ë“  ì¹´í…Œê³ ë¦¬ ì™„ë£Œ, {interval}ì´ˆ ëŒ€ê¸°")
        time.sleep(interval)

def start_local_crawler(
    db_config,
    openai_api_key,
    category_list,
    auto_crawl_interval=1800,
    signal_poll_interval=10
):
    """
    ë¡œì»¬ì—ì„œ ìë™ í¬ë¡¤ë§ ë£¨í”„ + ì‹ í˜¸ polling/ì²˜ë¦¬ ìŠ¤ë ˆë“œë¥¼ ë™ì‹œì— ì‹¤í–‰
    """
    # 1. ìë™ í¬ë¡¤ë§ìš© ìŠ¤ë ˆë“œ
    t1 = threading.Thread(
        target=auto_crawl_loop,
        args=(db_config, openai_api_key, category_list, auto_crawl_interval),
        daemon=True
    )
    t1.start()

    # 2. ì‹ í˜¸ polling/ì²˜ë¦¬ìš© ìŠ¤ë ˆë“œ (ì‹ í˜¸ ê°ì§€ ì‹œ â†’ ì¹´í…Œê³ ë¦¬ ë¦¬ë·° í¬ë¡¤ë§/ìš”ì•½/ì €ì¥)
    t2 = threading.Thread(
        target=poll_and_process_signal,
        args=(db_config["host"], db_config["user"], db_config["password"], db_config["db"], openai_api_key, signal_poll_interval),
        daemon=True
    )
    t2.start()

    logger.info("âœ… ìë™ í¬ë¡¤ë§/ì‹ í˜¸ polling ìŠ¤ë ˆë“œ ëª¨ë‘ ì‹œì‘")
    # ë©”ì¸ ìŠ¤ë ˆë“œëŠ” ë¬´í•œ ëŒ€ê¸°
    while True:
        time.sleep(3600)